{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f941f9",
   "metadata": {},
   "source": [
    "# Math 579 Advanced Mathematical Analysis – Project\n",
    "---\n",
    "**Date:** 2025-04-21\n",
    "**Name:** Samisoni Palu  \n",
    "**Instructor:** Dr. Sun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51b7c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import json\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849aa8e6",
   "metadata": {},
   "source": [
    "## Utils\n",
    "Board data\n",
    "---\n",
    "`generate_uci_move_list`\n",
    "- list all possible moves as a 2-tuple of from_square, to_square\n",
    "- tweaked for promotion move counts\n",
    "- will Include Redundant or Invalid Moves\n",
    "    - **`a1a1`, `d4d4`**, etc. → no actual move is made\n",
    "    - **Illegal under any real game condition**\n",
    "    - Also includes nonsense like `h2h8` (rook-style moves for pawns)\n",
    "\n",
    "But remember:  \n",
    "> You’re not saying “these are all valid moves”  \n",
    "> **this is the full move *vocabulary***—the possible *labels* in a classification task.\n",
    "> That is, our **vocabulary** list is all the two-tuple pairings of squares, e.g. (`h2g3`), with promotions\n",
    "\n",
    "Our total vocabulary size count includes the sum of\n",
    "- 64x64 (each pairing of squares)\n",
    "- 8 (number of columns) x 2 (white-black promotions) x 4 (choices of upgrade) x 3 (capture types) - 16 (edge cases)\n",
    "\n",
    "We should expect our logits vector to have size **4272**. \n",
    "\n",
    "**Benefits of the chosen Vocabulary**\n",
    "\n",
    "1. Simplicity in Output Shape\n",
    "    - 1-to-1 mapping: index ↔ UCI\n",
    "    - You don’t need dynamic output heads or custom decoders\n",
    "    - You can store logits as `torch.tensor([4672])` and just mask out illegal ones at runtime\n",
    "\n",
    "2. Consistency\n",
    "    - Your label space is fixed across:\n",
    "      - Training\n",
    "      - Inference\n",
    "      - Evaluation\n",
    "\n",
    "3. Non-moves Never Get Trained On\n",
    "    - No master ever plays `a1a1`\n",
    "    - So those output indices **never get gradient updates**\n",
    "    - They just sit in the model—harmless dead neurons\n",
    "\n",
    "**Why You Might Remove Redundant Moves**\n",
    "\n",
    "1. Smaller Output Space\n",
    "    - Saves compute on final linear layer and softmax\n",
    "    - Slightly faster training (maybe)\n",
    "\n",
    "2. Model Capacity Allocation\n",
    "    - You force the network to **only ever consider valid move templates**\n",
    "    - Could lead to sharper learning curve\n",
    "\n",
    "But you pay with **more complexity**:\n",
    "- Dynamic move indexing\n",
    "- Pre-mask needs to align with training mask\n",
    "- Harder debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb991bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uci_move_list():\n",
    "    all_moves = set()\n",
    "    for from_sq in chess.SQUARES:\n",
    "        for to_sq in chess.SQUARES:\n",
    "            move = chess.Move(from_sq, to_sq)\n",
    "            all_moves.add(move.uci())\n",
    "            # Add promotions\n",
    "            for promo in [chess.QUEEN, chess.ROOK, chess.BISHOP, chess.KNIGHT]:\n",
    "                from_rank = chess.square_rank(from_sq)\n",
    "                to_rank = chess.square_rank(to_sq)\n",
    "                from_file = chess.square_file(from_sq)\n",
    "                to_file = chess.square_file(to_sq)\n",
    "                # Only allow forward promotion (white or black)\n",
    "                if (from_rank , to_rank) in [(6, 7), (1, 0)]:  # white/black promotion ranks\n",
    "                    if abs(from_file - to_file) <= 1:         # straight or diagonal\n",
    "                        promo_move = chess.Move(from_sq, to_sq, promotion=promo)\n",
    "                        all_moves.add(promo_move.uci())\n",
    "    return sorted(all_moves)\n",
    "\n",
    "\n",
    "def save_move_index_map(path=\"data/move_index_map.json\"):\n",
    "    moves = generate_uci_move_list()\n",
    "    uci_to_index = {uci: i for i, uci in enumerate(moves)}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(uci_to_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5de140c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits size =  4272\n"
     ]
    }
   ],
   "source": [
    "move_list = generate_uci_move_list()\n",
    "print('Logits size = ',len(move_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIECE_TO_IDX = {\n",
    "    None: 0,\n",
    "    chess.PAWN: 1,\n",
    "    chess.KNIGHT: 2,\n",
    "    chess.BISHOP: 3,\n",
    "    chess.ROOK: 4,\n",
    "    chess.QUEEN: 5,\n",
    "    chess.KING: 6,\n",
    "}\n",
    "\n",
    "def encode_board(board: chess.Board):\n",
    "    board_array = np.zeros((8, 8), dtype=np.int64)\n",
    "    \n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        row = 7 - (square // 8)\n",
    "        col = square % 8\n",
    "\n",
    "        if piece is not None:\n",
    "            base = PIECE_TO_IDX[piece.piece_type]\n",
    "            offset = 0 if piece.color == chess.WHITE else 6\n",
    "            board_array[row][col] = base + offset\n",
    "        else:\n",
    "            board_array[row][col] = 0  # empty\n",
    "\n",
    "    return board_array  # shape: [8,8] of ints in [0,12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77ddd9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  8,  9, 11, 12,  9,  8, 10],\n",
       "       [ 7,  7,  7,  7,  7,  7,  7,  7],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [ 4,  2,  3,  5,  6,  3,  2,  4]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = chess.Board()\n",
    "encode_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=32, num_moves=4672):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(13, embedding_dim)  # 13 tokens -> vector\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),                # [8,8,32] -> [2048]\n",
    "            nn.Linear(8*8*embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_moves)   # Final logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # x: [B, 8, 8]\n",
    "        x = self.embed(x)  # [B, 8, 8, D]\n",
    "        x = x.permute(0, 3, 1, 2)  # [B, D, 8, 8] (optional conv-style order)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479fa28",
   "metadata": {},
   "source": [
    "## Goal Recap:\n",
    "We want a neural network that takes:\n",
    "- Input: an `8×8` grid of piece tokens (entries are integers from 0 to 12)\n",
    "- Output: a **4672-dimensional logits vector**\n",
    "\n",
    "---\n",
    "\n",
    "### CLASS STRUCTURE: `PolicyNet`\n",
    "\n",
    "```python\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=32, num_moves=4672):\n",
    "```\n",
    "\n",
    "- **`embedding_dim=32`**: each board square will be represented by a **32-dimensional vector**.\n",
    "- **`num_moves=4272`**: the size of **output layer**, corresponding to all possible moves.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "        super().__init__()\n",
    "```\n",
    "\n",
    "- Standard for initializing the parent class (`nn.Module`).\n",
    "\n",
    "---\n",
    "\n",
    "### Embedding Layer\n",
    "\n",
    "```python\n",
    "        self.embed = nn.Embedding(13, embedding_dim)\n",
    "```\n",
    "\n",
    "- This layer turns each square’s integer (0–12) into a vector of dimension `[embedding_dim]`.\n",
    "- `[8,8]` board → `[8,8,32]` tensor.\n",
    "\n",
    "---\n",
    "\n",
    "### Fully Connected Network (MLP)\n",
    "These are our hidden and output logits layer. \n",
    "```python\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),                \n",
    "            nn.Linear(8*8*embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_moves)\n",
    "        )\n",
    "```\n",
    "\n",
    "#### `nn.Flatten()`\n",
    "- Converts `[B, 8, 8, 32]` into `[B, 2048]`, similar to .view\n",
    "- Needed to feed into `Linear` layers\n",
    "\n",
    "#### `nn.Linear(2048, 512)`\n",
    "- Fully connected layer reducing 2048 features to 512 neurons\n",
    "\n",
    "#### `nn.ReLU()`\n",
    "- Non-linear activation to let the model learn more complex patterns\n",
    "\n",
    "#### `nn.Linear(512, num_moves)`\n",
    "- Final layer: predicts logit value for each of the 4672 moves\n",
    "\n",
    "---\n",
    "\n",
    "### `forward` Function\n",
    "\n",
    "```python\n",
    "    def forward(self, x):  # x: [B, 8, 8]\n",
    "        x = self.embed(x)  # [B, 8, 8, D]\n",
    "        x = x.permute(0, 3, 1, 2)  # Optional: [B, D, 8, 8]\n",
    "        return self.fc(x)\n",
    "```\n",
    "\n",
    "- **Input**: `x` is a batch of boards, shape `[batch_size, 8, 8]`\n",
    "- **Embedding**: turns each square into a vector: `[B, 8, 8, 32]`\n",
    "- **FC Network**: outputs a `[B, 4672]` tensor of logits\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- network **understands piece identity** through embeddings.\n",
    "- it **flattens** the board to make a prediction using fully connected layers.\n",
    "- The output is a **score for every possible move**, and later **mask illegal ones**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028e809",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
